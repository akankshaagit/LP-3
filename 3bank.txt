Given a bank customer, build a neural networkbased classifier that can determine whether they will
leave or not in the next 6 months.

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.svm import SVC, LinearSVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
from sklearn import preprocessing

df = pd.read_csv('/content/drive/MyDrive/lp3/churn_modelling.csv')

df.info()

df.head()

df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)

df.isna().sum()

df.describe()

plt.xlabel('Exited')
plt.ylabel('Count')
df['Exited'].value_counts().plot.bar()
plt.show()

X=df.iloc[:, :df.shape[1]-1].values       #Independent Variables
y=df.iloc[:, -1].values                   #Dependent Variable
X.shape, y.shape

print(X[:8,1], '... will now become: ')

label_X_country_encoder = LabelEncoder()
X[:,1] = label_X_country_encoder.fit_transform(X[:,1])
print(X[:8,1])

print(X[:6,2], '... will now become: ')

label_X_gender_encoder = LabelEncoder()
X[:,2] = label_X_gender_encoder.fit_transform(X[:,2])
print(X[:6,2])

transform = ColumnTransformer([("countries", OneHotEncoder(), [1])], remainder="passthrough") # 1 is the country column
X = transform.fit_transform(X)
X

X = X[:,1:]
X.shape

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

sc=StandardScaler()
X_train[:,np.array([2,4,5,6,7,10])] = sc.fit_transform(X_train[:,np.array([2,4,5,6,7,10])])
X_test[:,np.array([2,4,5,6,7,10])] = sc.transform(X_test[:,np.array([2,4,5,6,7,10])])

sc=StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)
X_train

from tensorflow.keras.models import Sequential

# Initializing the ANN
classifier = Sequential()

from tensorflow.keras.layers import Dense

# The amount of nodes (dimensions) in hidden layer should be the average of input and output layers, in this case 6.
# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)
classifier.add(Dense(activation = 'relu', input_dim = 11, units=256, kernel_initializer='uniform'))

# Adding the hidden layer
classifier.add(Dense(activation = 'relu', units=512, kernel_initializer='uniform'))
classifier.add(Dense(activation = 'relu', units=256, kernel_initializer='uniform'))
classifier.add(Dense(activation = 'relu', units=128, kernel_initializer='uniform'))

# Adding the output layer
# Notice that we do not need to specify input dim. 
# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)
# We use the sigmoid because we want probability outcomes
classifier.add(Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform'))

# Create optimizer with default learning rate
# sgd_optimizer = tf.keras.optimizers.SGD()
# Compile the model
classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

classifier.summary()

classifier.fit(
    X_train, y_train,           
    validation_data=(X_test,y_test),
    epochs=20,
    batch_size=32
)

y_pred = classifier.predict(X_test)
y_pred

# To use the confusion Matrix, we need to convert the probabilities that a customer will leave the bank into the form true or false. 
# So we will use the cutoff value 0.5 to indicate whether they are likely to exit or not.
y_pred = (y_pred > 0.5)
y_pred

from sklearn.metrics import accuracy_score,confusion_matrix,ConfusionMatrixDisplay
accuracy_score(y_test,y_pred)
cm = confusion_matrix(y_test,y_pred)
display = ConfusionMatrixDisplay(cm)
display.plot()


from sklearn.metrics import confusion_matrix,classification_report

cm1 = confusion_matrix(y_test, y_pred)
cm1

print(classification_report(y_test, y_pred))

accuracy_model1 = ((cm1[0][0]+cm1[1][1])*100)/(cm1[0][0]+cm1[1][1]+cm1[0][1]+cm1[1][0])
print (accuracy_model1, '% of testing data was classified correctly')

==================================================================================================================================================

What specific features in the dataset do you believe are most indicative of whether a customer will leave the bank? Why?
Consider factors such as customer demographics, account details, transaction history, and previous interactions with the bank that might influence a customer's decision to stay or leave.

How would you interpret the accuracy score and confusion matrix results? What do they tell you about the model's performance?
Evaluate the model's ability to correctly predict churn vs. non-churn customers and the implications of false positives and false negatives in this context.

Bank customer churn refers to the phenomenon where customers discontinue their relationship with a bank, either by closing their accounts or switching to a different financial institution. This can occur for various reasons

How can the bank use the results from this model?
The bank can use the model's predictions to identify at-risk customers and implement targeted marketing campaigns or retention strategies to reduce churn rates.

What hyperparameters did you tune for the neural network?
I tuned hyperparameters such as the number of layers, number of nodes in each layer, learning rate, and batch size to optimize the model's performance.

What is customer churn, and why is it important for banks?
Customer churn refers to the rate at which customers stop doing business with a bank. It's important for banks to manage churn to maintain profitability and customer loyalty.

Why did you choose to use a neural network for this classification task?
Neural networks can model complex relationships and interactions between features, making them suitable for capturing patterns in customer data that predict churn.



